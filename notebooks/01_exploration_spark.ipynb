{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f267ffc",
   "metadata": {},
   "source": [
    "# Exploration initiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95eddca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "\n",
    "\n",
    "DATA_DIR = \"../data_ecf\"\n",
    "CONSO_RAW_PATH = os.path.join(DATA_DIR, \"consommations_raw.csv\")\n",
    "METEO_PATH = os.path.join(DATA_DIR, \"meteo_raw.csv\")\n",
    "BATIMENTS_PATH = os.path.join(DATA_DIR, \"batiments.csv\")\n",
    "TARIF_ENERGIE_PATH = os.path.join(DATA_DIR, \"tarifs_energie.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0d10f",
   "metadata": {},
   "source": [
    "## Session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac38d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.7\n",
      "Spark UI: http://host.docker.internal:4041\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ECF2\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Reduire les logs\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Spark UI: {spark.sparkContext.uiWebUrl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746a9b3",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c41aac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes: 7,758,868\n",
      "Nombre de colonnes: 5\n"
     ]
    }
   ],
   "source": [
    "df_conso_raw = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(CONSO_RAW_PATH)\n",
    "\n",
    "print(f\"Nombre de lignes: {df_conso_raw.count():,}\")\n",
    "print(f\"Nombre de colonnes: {len(df_conso_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1601d67c",
   "metadata": {},
   "source": [
    "## Schema infere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b1899b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- batiment_id: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- type_energie: string (nullable = true)\n",
      " |-- consommation: string (nullable = true)\n",
      " |-- unite: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_conso_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bab40f",
   "metadata": {},
   "source": [
    "## Problèmes de typage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f77fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de formats de timestamp:\n",
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2023-12-21 13:00:00|\n",
      "|11/29/2024 04:00:00|\n",
      "|09/15/2024 18:00:00|\n",
      "|20/12/2023 07:00   |\n",
      "|29/04/2024 13:00   |\n",
      "|2024-06-15T14:00:00|\n",
      "|22/03/2024 11:00   |\n",
      "|2023-04-07 13:00:00|\n",
      "|2024-03-11T11:00:00|\n",
      "|08/21/2024 17:00:00|\n",
      "|2024-05-27 04:00:00|\n",
      "|08/02/2023 16:00   |\n",
      "|2024-11-23 17:00:00|\n",
      "|2023-07-06T05:00:00|\n",
      "|2024-04-30 02:00:00|\n",
      "|08/12/2023 06:00   |\n",
      "|16/11/2024 21:00   |\n",
      "|12/08/2024 04:00:00|\n",
      "|2024-05-27 10:00:00|\n",
      "|11/03/2023 09:00:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Differents formats de timestamp\n",
    "print(\"Exemples de formats de timestamp:\")\n",
    "df_conso_raw.select(\"timestamp\").distinct().show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85ccd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs non numeriques: 38,975\n",
      "+------------+\n",
      "|consommation|\n",
      "+------------+\n",
      "|        null|\n",
      "|         N/A|\n",
      "|      erreur|\n",
      "|         ---|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# La colonne 'consommation' est en string car elle contient des virgules et des valeurs textuelles\n",
    "# Examinons les valeurs non numeriques\n",
    "\n",
    "# Valeurs qui ne peuvent pas etre converties en nombre\n",
    "df_non_numeric = df_conso_raw.filter(\n",
    "    ~F.col(\"consommation\").rlike(\"^-?[0-9]+[.,]?[0-9]*$\")\n",
    ")\n",
    "\n",
    "print(f\"Nombre de valeurs non numeriques: {df_non_numeric.count():,}\")\n",
    "df_non_numeric.select(\"consommation\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a18234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs avec virgule: 925,392\n",
      "+------------+\n",
      "|consommation|\n",
      "+------------+\n",
      "|       10,10|\n",
      "|       72,29|\n",
      "|       17,82|\n",
      "|        0,92|\n",
      "|      290,65|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valeurs avec virgule comme separateur decimal\n",
    "df_with_comma = df_conso_raw.filter(F.col(\"consommation\").contains(\",\"))\n",
    "print(f\"Nombre de valeurs avec virgule: {df_with_comma.count():,}\")\n",
    "df_with_comma.select(\"consommation\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d72704c",
   "metadata": {},
   "source": [
    "## Statistiques descriptives par type d'énergie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a28680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistiques par type d'énergie:\n",
      "+------------+-------+------+-------+--------+--------+------+\n",
      "|type_energie|  count|  mean| stddev|     min|     max|median|\n",
      "+------------+-------+------+-------+--------+--------+------+\n",
      "|         eau|2573156|204.36|2398.57| -657.01|49999.23|  7.52|\n",
      "| electricite|2573364|430.64|2429.51|-4003.35|49999.13|108.56|\n",
      "|         gaz|2573373|560.94|2465.81|-5963.49|49999.49|160.57|\n",
      "+------------+-------+------+-------+--------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convertir value en double (en remplacant la virgule par un point)\n",
    "df_conso_numeric = df_conso_raw.withColumn(\n",
    "    \"conso_clean\",\n",
    "    F.regexp_replace(F.col(\"consommation\"), \",\", \".\").cast(\"double\")\n",
    ")\n",
    "\n",
    "# Statistiques par polluant (en ignorant les valeurs nulles)\n",
    "stats_by_energy = df_conso_numeric.filter(F.col(\"conso_clean\").isNotNull()) \\\n",
    "    .groupBy(\"type_energie\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.round(F.mean(\"conso_clean\"), 2).alias(\"mean\"),\n",
    "        F.round(F.stddev(\"conso_clean\"), 2).alias(\"stddev\"),\n",
    "        F.round(F.min(\"conso_clean\"), 2).alias(\"min\"),\n",
    "        F.round(F.max(\"conso_clean\"), 2).alias(\"max\"),\n",
    "        F.round(F.expr(\"percentile(conso_clean, 0.5)\"), 2).alias(\"median\")\n",
    "    ) \\\n",
    "    .orderBy(\"type_energie\")\n",
    "\n",
    "print(\"Statistiques par type d'énergie:\")\n",
    "stats_by_energy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a4285ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs negatives:\n",
      "+------------+-----+\n",
      "|type_energie|count|\n",
      "+------------+-----+\n",
      "|         eau|12945|\n",
      "|         gaz|12997|\n",
      "| electricite|12968|\n",
      "+------------+-----+\n",
      "\n",
      "\n",
      "Valeurs > 15000 :\n",
      "+------------+-----+\n",
      "|type_energie|count|\n",
      "+------------+-----+\n",
      "|         eau|12810|\n",
      "|         gaz|12764|\n",
      "| electricite|12986|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifier les valeurs aberrantes\n",
    "print(\"Valeurs negatives:\")\n",
    "df_conso_numeric.filter(F.col(\"conso_clean\") < 0).groupBy(\"type_energie\").count().show()\n",
    "\n",
    "print(\"\\nValeurs > 15000 :\")\n",
    "df_conso_numeric.filter(F.col(\"conso_clean\") > 15000).groupBy(\"type_energie\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd863bf",
   "metadata": {},
   "source": [
    "## Bâtiment avec le plus de mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01d293be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+-----------+-------+----------+------------------+------------------+------------------+\n",
      "|batiment_id|                nom|       type|commune|surface_m2|annee_construction|classe_energetique|nb_occupants_moyen|\n",
      "+-----------+-------------------+-----------+-------+----------+------------------+------------------+------------------+\n",
      "|    BAT0001|      Ecole Paris 1|      ecole|  Paris|      1926|              1978|                 E|               225|\n",
      "|    BAT0002|      Ecole Paris 2|      ecole|  Paris|      1156|              2004|                 C|               402|\n",
      "|    BAT0003|      Ecole Paris 3|      ecole|  Paris|      1695|              2014|                 D|               219|\n",
      "|    BAT0004|Mediatheque Paris 4|mediatheque|  Paris|       907|              2019|                 C|               121|\n",
      "|    BAT0005|    Piscine Paris 5|    piscine|  Paris|      3913|              1950|                 G|               242|\n",
      "|    BAT0006|     Mairie Paris 6|     mairie|  Paris|      1165|              1985|                 E|                63|\n",
      "|    BAT0007|    Gymnase Paris 7|    gymnase|  Paris|      1209|              1998|                 C|                73|\n",
      "|    BAT0008|    Gymnase Paris 8|    gymnase|  Paris|      2236|              1955|                 G|               117|\n",
      "|    BAT0009|       Ecole Lyon 9|      ecole|   Lyon|      2350|              2020|                 B|               140|\n",
      "|    BAT0010|Mediatheque Lyon 10|mediatheque|   Lyon|      1240|              1974|                 G|               103|\n",
      "+-----------+-------------------+-----------+-------+----------+------------------+------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chargement des bâtiments\n",
    "df_batiments = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(BATIMENTS_PATH)\n",
    "\n",
    "df_batiments.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744179da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 des bâtiments avec le plus d'enregistrements:\n",
      "+-----------+--------------------+----------+------+-----+\n",
      "|batiment_id|                 nom|   commune|  type|count|\n",
      "+-----------+--------------------+----------+------+-----+\n",
      "|    BAT0073|Mairie Strasbourg 73|Strasbourg|mairie|53156|\n",
      "+-----------+--------------------+----------+------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Nombre d'enregistrements par bâtiments\n",
    "records_by_bat = df_conso_raw.groupBy(\"batiment_id\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "\n",
    "# Joindre avec les infos des stations\n",
    "records_with_info = records_by_bat.join(\n",
    "    df_batiments,\n",
    "    on=\"batiment_id\",\n",
    "    how=\"left\"\n",
    ").select(\n",
    "    \"batiment_id\", \"nom\", \"commune\", \"type\", \"count\"\n",
    ")\n",
    "\n",
    "print(\"Top 1 des bâtiments avec le plus d'enregistrements:\")\n",
    "records_with_info.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8edc2b",
   "metadata": {},
   "source": [
    "## Audit de qualité des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ad828e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enregistrements: 7,758,868\n",
      "\n",
      "Problemes identifies:\n",
      "  - Valeurs non numeriques: 38,975 (0.50%)\n",
      "  - Valeurs avec virgule decimale: 925,392 (11.93%)\n",
      "  - Valeurs negatives: 38,910 (0.50%)\n",
      "  - Valeurs aberrantes (>15000): 38,560 (0.50%)\n",
      "  - Doublons: 152,134 (1.96%)\n",
      "  - Formats de dates multiples: 4 formats differents detectes\n"
     ]
    }
   ],
   "source": [
    "# Resume des problemes\n",
    "total = df_conso_raw.count()\n",
    "\n",
    "# Valeurs non numeriques\n",
    "non_numeric = df_conso_raw.filter(\n",
    "    ~F.col(\"consommation\").rlike(\"^-?[0-9]+[.,]?[0-9]*$\")\n",
    ").count()\n",
    "\n",
    "# Valeurs avec virgule\n",
    "with_comma = df_conso_raw.filter(F.col(\"consommation\").contains(\",\")).count()\n",
    "\n",
    "# Valeurs negatives (apres conversion)\n",
    "negative = df_conso_numeric.filter(F.col(\"conso_clean\") < 0).count()\n",
    "\n",
    "# Valeurs aberrantes > 15000\n",
    "outliers = df_conso_numeric.filter(F.col(\"conso_clean\") > 15000).count()\n",
    "\n",
    "# Doublons\n",
    "duplicates = total - df_conso_raw.dropDuplicates([\"batiment_id\", \"timestamp\", \"type_energie\"]).count()\n",
    "\n",
    "\n",
    "print(f\"Total enregistrements: {total:,}\")\n",
    "print()\n",
    "print(f\"Problemes identifies:\")\n",
    "print(f\"  - Valeurs non numeriques: {non_numeric:,} ({non_numeric/total*100:.2f}%)\")\n",
    "print(f\"  - Valeurs avec virgule decimale: {with_comma:,} ({with_comma/total*100:.2f}%)\")\n",
    "print(f\"  - Valeurs negatives: {negative:,} ({negative/total*100:.2f}%)\")\n",
    "print(f\"  - Valeurs aberrantes (>15000): {outliers:,} ({outliers/total*100:.2f}%)\")\n",
    "print(f\"  - Doublons: {duplicates:,} ({duplicates/total*100:.2f}%)\")\n",
    "print(f\"  - Formats de dates multiples: 4 formats differents detectes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44c2755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
